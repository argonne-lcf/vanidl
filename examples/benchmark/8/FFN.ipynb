{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLProfile Example using Distributed FFN Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set imports and neccessary environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VANIDL_DIR=\"{}\".format(pathlib.Path(os.getcwd()).parent.parent.parent.absolute())\n",
    "sys.path.insert(0, VANIDL_DIR)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"DARSHAN_DIR\"] = \"/soft/perftools/darshan/darshan-3.1.8\"\n",
    "os.environ[\"VANIDL_DIR\"] = VANIDL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=1)\n",
    "class color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create instrance of DL Profile and load the darshan file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.vanidl import VaniDL\n",
    "profile = VaniDL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f /tmp/temp_analysis/ffn_run1_p8*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================================================] 100.0% 17315390 of 17315390 Parsing DXT File \n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ec0ff8f36b9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mDATAPATH_INCLUDES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/dhari/darshan-logs/benchmark/ffn/ffn_run1_p8.darshan\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_paths_include\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDATAPATH_INCLUDES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Darshan Trace loaded Successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/mira-home/dhari/code/dlprofiler/src/vanidl.py\u001b[0m in \u001b[0;36mLoad\u001b[0;34m(self, darshan_file, preprocessed_dir, data_paths_include, tensorflow_logs_dir)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio_df_dxt_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxt_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_dxt_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxt_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mio_df_dxt_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxt_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio_df_dxt_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3x/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3226\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3227\u001b[0m         )\n\u001b[0;32m-> 3228\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3x/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnicodeWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mwriter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3x/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3x/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    354\u001b[0m         )\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mlibwriters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_csv_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mpandas/_libs/writers.pyx\u001b[0m in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "DATAPATH_INCLUDES = []\n",
    "status = profile.Load(\"/home/dhari/darshan-logs/benchmark/ffn/ffn_run1_p8.darshan\", data_paths_include=DATAPATH_INCLUDES)\n",
    "if status:\n",
    "    print(\"Darshan Trace loaded Successfully!\")\n",
    "else:\n",
    "    print(\"Darshan Trace load Failed!\")\n",
    "    print(profile._error_str())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Profile object to analyze the darshan I/O trace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify if object works\n",
    "\n",
    "The GetDXTAsDF() function enables users to perform analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "df = profile.GetDXTAsDF()\n",
    "pp.pprint(\"Files used in the application\")\n",
    "pp.pprint(df['Filename'].unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect the summary of the Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = profile.GetSummary()\n",
    "print(\"\\n\")\n",
    "print(color.BOLD + \"Data Access Summary (from Darshan):\"+ color.END)\n",
    "print(\"Total Job time\\t\\t\\t:\\t{:0.2f} seconds\".format(summary['job_time']))\n",
    "#FIXME: calculate time per rank and then take max across it.\n",
    "print(\"Time spent in I/O\\t\\t:\\t{:0.2f} seconds\".format(summary['total_io_time']))\n",
    "print(\"% Time spent in I/O\\t\\t:\\t{:0.2f}%\".format(float(summary['total_io_time'])*100/summary['job_time']))\n",
    "print(\"Total Data Accessed\\t\\t:\\t{:0.2f} GB\".format(float(summary['total_io_bytes'])/1024.0/1024.0/1024.0))\n",
    "print(\"Data Access Modules used\\t:\\t{}\".format(summary['io_interface_used']))\n",
    "print(\"Data Operations\\t\\t\\t:\\t{}\".format(summary['io_operations_used']))\n",
    "print(\"# of files used\\t\\t\\t:\\t{}\".format(len(summary['files_used'])))\n",
    "print(\"# of MPI Ranks\\t\\t\\t:\\t{:0.0f} ranks\".format(summary['num_ranks']))\n",
    "      \n",
    "print(color.UNDERLINE + \"Data Transfer size:\"+ color.END)\n",
    "print(\"\\tMin,Max\\t\\t\\t:\\t{:0.0f} bytes and {:0.0f} bytes\".format(summary['data_transfer_size']['min'],summary['data_transfer_size']['max']))\n",
    "print(\"\\tAverage\\t\\t\\t:\\t{:0.0f} bytes\".format(summary['data_transfer_size']['mean']))\n",
    "print(\"\\tMedian\\t\\t\\t:\\t{:0.0f} bytes\".format(summary['data_transfer_size']['median']))\n",
    "      \n",
    "print(color.UNDERLINE + \"Data Transfer bandwidth: (per rank)\"+ color.END)\n",
    "print(\"\\tMin,Max\\t\\t\\t:\\t{:0.0f} B/s and {:0.0f} MB/s\".format(summary['data_transfer_bandwidth']['min'],summary['data_transfer_bandwidth']['max']/1024.0/1024.0))\n",
    "print(\"\\tAverage\\t\\t\\t:\\t{:0.0f} MB/s\".format(summary['data_transfer_bandwidth']['mean']/1024.0/1024.0))\n",
    "print(\"\\tMedian\\t\\t\\t:\\t{:0.0f} MB/s\".format(summary['data_transfer_bandwidth']['median']/1024.0/1024.0))\n",
    "      \n",
    "print(color.UNDERLINE + \"Access Pattern:\"+ color.END)\n",
    "print(\"\\tSequential\\t\\t:\\t{:0.2f}%\".format(float(summary['access_pattern']['sequential'])))\n",
    "print(\"\\tConsecutive\\t\\t:\\t{:0.2f}%\".format(float(summary['access_pattern']['consecutive'])))\n",
    "#An I/O op issued at an offset greater than where the previous I/O op ended.\n",
    "#An I/O op issued at the offset immediately after the end of the previous I/O\n",
    "\n",
    "print(\"\\n\")\n",
    "print(color.BOLD + \"Files Summary:\"+ color.END)\n",
    "print(\"File Types\\t\\t\\t:\\t{}\".format(summary['file_used_summary']['types']))\n",
    "print(color.UNDERLINE + \"Dataset Size:\"+ color.END)\n",
    "print(\"\\tTotal\\t\\t\\t:\\t{:0.3f} GB\".format(float(summary['file_used_summary']['size']['total'])/1024.0/1024.0/1024.0))\n",
    "print(\"\\tMin,Max\\t\\t\\t:\\t{:0.3f} GB and {:0.3f} GB\".format(float(summary['file_used_summary']['size']['min'])/1024.0/1024.0/1024.0,float(summary['file_used_summary']['size']['max'])/1024.0/1024.0/1024.0))\n",
    "print(\"\\tAverage\\t\\t\\t:\\t{:0.3f} GB\".format(float(summary['file_used_summary']['size']['mean'])/1024.0/1024.0/1024.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(\"Job time : {} seconds\".format(profile.GetJobTime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pp.pprint(\"Time spent by application on I/O: {} seconds\".format(profile.GetIOTime()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I/O time spent on each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in df['Filename'].unique():\n",
    "    print(\"I/O time for file {}: {:0.2f} seconds\".format(file,profile.GetIOTime(filepath=file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I/O Time spent per rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rank in df['Rank'].unique()[:16]:\n",
    "    print(\"I/O time for rank {}: {:0.2f} seconds\".format(rank,profile.GetIOTime(rank=rank)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Total I/O performed by application: {:0.2f} GB\".format(float(profile.GetIOSize())/1024.0/1024.0/1024.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I/O performed on each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in df['Filename'].unique()[:16]:\n",
    "    print(\"I/O performed on file {}: {:0.2f} MB\".format(file,float(profile.GetIOSize(filepath=file))/1024.0/1024.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for rank in df['Rank'].unique()[:16]:\n",
    "    print(\"I/O performed by rank {}: {:0.2f} MB\".format(rank, float(profile.GetIOSize(rank=rank))/1024.0/1024.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = profile.GetFileSizes()\n",
    "for key in sizes:\n",
    "    sizes[key] = sizes[key]/1024.0/1024.0\n",
    "print(\"Size of dataset (MB)\")\n",
    "pp.pprint(sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How application access data over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = profile.CreateIOTimeline(time_step=0.001)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.xlabel(\"Timeline (ms)\")\n",
    "plt.ylabel(\"# of Operations (ms)\")\n",
    "plt.grid()\n",
    "plt.plot(tl['time_step'], tl['operation_count']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "plt.grid()\n",
    "plt.plot(tl['time_step'], tl['io_bytes']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How files are accessed over the duration of the Job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in df['Filename'].unique():\n",
    "    tl = profile.CreateIOTimeline(filepath=file, time_step=0.001)\n",
    "    tl.plot(x='time_step',y='operation_count', title=file)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show how each file is accessed by each rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rank in df['Rank'].unique()[:16]:\n",
    "    tl = profile.CreateIOTimeline(rank=rank, time_step=0.001)\n",
    "    tl.plot(x='time_step',y='operation_count', title=rank)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transfer Size distribution within the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_df = profile.GetIORequestDistribution()\n",
    "df['Length'].plot(kind='hist', figsize=(5, 3),bins=1000);\n",
    "plt.xlabel(\"Transfer Size (bytes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in df['Filename'].unique():\n",
    "    #tl = profile.GetIORequestDistribution(filepath=file, bins=50)\n",
    "    tl = df[df[\"Filename\"].eq(file)]\n",
    "    tl['Length'].plot(kind='hist', figsize=(5, 3),bins=50);\n",
    "    plt.xlabel(\"Transfer Size (bytes)\")\n",
    "    plt.title(file)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transfer Sizes per Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rank in df['Rank'].unique()[:16]:\n",
    "    tl = profile.GetIORequestDistribution(rank=rank)\n",
    "    tl.plot(kind='bar', figsize=(10, 4), title=rank)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File summary of each file accessed by the Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=1)\n",
    "for file in df['Filename'].unique():\n",
    "    if 'h5' in file:\n",
    "        pp.pprint(profile.GetFileSummary(file,ext='h5'))\n",
    "    else:\n",
    "        pp.pprint(profile.GetFileSummary(file,ext='tfrecord',tf_record_features=dict(\n",
    "                                        center=tf.io.FixedLenFeature(shape=[1, 3], dtype=tf.int64),\n",
    "                                        label_volume_name=tf.io.FixedLenFeature(shape=[1], dtype=tf.string),)\n",
    "                                        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
